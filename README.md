# Curso de Databricks: Construindo Pipelines de Dados com Airflow e Azure Databricks

Este reposit√≥rio cont√©m os c√≥digos e configura√ß√µes desenvolvidos durante o curso **"Databricks: Construindo Pipelines de Dados com Airflow e Azure Databricks"**. O objetivo principal √© demonstrar como construir uma pipeline de dados completa, desde a coleta at√© a entrega de relat√≥rios automatizados, utilizando ferramentas modernas de engenharia de dados.

## üìå O que √© feito no curso

Ao longo do curso, desenvolvemos uma solu√ß√£o de ponta a ponta com os seguintes componentes:

- üîó **Conex√£o com uma API de taxas de c√¢mbio**  
  Realiza a coleta de dados hist√≥ricos de taxas de convers√£o de moedas, com um recorte dos √∫ltimos dois meses.

- üßπ **Tratamento e transforma√ß√£o dos dados**  
  Os dados brutos da API s√£o processados e estruturados, prontos para an√°lises e visualiza√ß√µes.

- üîÅ **Orquestra√ß√£o com Apache Airflow**  
  Toda a pipeline de coleta, processamento e envio √© automatizada com o uso de DAGs no Airflow.

- ü§ñ **Bot do Slack para envio de relat√≥rios**  
  Um bot √© configurado para enviar diariamente um relat√≥rio no Slack com as cota√ß√µes do dia anterior (D-1), incluindo gr√°ficos e an√°lises.

## üõ†Ô∏è Tecnologias Utilizadas

- [Azure Databricks](https://azure.microsoft.com/pt-br/products/databricks/)
- [Apache Airflow](https://airflow.apache.org/)
- [Slack API](https://api.slack.com/)
- Python
- APIs de c√¢mbio (ex.: [exchangerate.host](https://exchangerate.host/) ou similares)
