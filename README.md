# Curso de Databricks: Construindo Pipelines de Dados com Airflow e Azure Databricks

Este repositÃ³rio contÃ©m os cÃ³digos e configuraÃ§Ãµes desenvolvidos durante o curso **"Databricks: Construindo Pipelines de Dados com Airflow e Azure Databricks"**. O objetivo principal Ã© demonstrar como construir uma pipeline de dados completa, desde a coleta atÃ© a entrega de relatÃ³rios automatizados, utilizando ferramentas modernas de engenharia de dados.

## ğŸ“Œ O que Ã© feito no curso

Ao longo do curso, desenvolvemos uma soluÃ§Ã£o de ponta a ponta com os seguintes componentes:

- ğŸ”— **ConexÃ£o com uma API de taxas de cÃ¢mbio**  
  Realiza a coleta de dados histÃ³ricos de taxas de conversÃ£o de moedas, com um recorte dos Ãºltimos dois meses.

- ğŸ§¹ **Tratamento e transformaÃ§Ã£o dos dados**  
  Os dados brutos da API sÃ£o processados e estruturados, prontos para anÃ¡lises e visualizaÃ§Ãµes.

- ğŸ” **OrquestraÃ§Ã£o com Apache Airflow**  
  Toda a pipeline de coleta, processamento e envio Ã© automatizada com o uso de DAGs no Airflow.

- ğŸ¤– **Bot do Slack para envio de relatÃ³rios**  
  Um bot Ã© configurado para enviar diariamente um relatÃ³rio no Slack com as cotaÃ§Ãµes do dia anterior (D-1), incluindo grÃ¡ficos e anÃ¡lises.

## ğŸ› ï¸ Tecnologias Utilizadas

- [Azure Databricks](https://azure.microsoft.com/pt-br/products/databricks/)
- [Apache Airflow](https://airflow.apache.org/)
- [Slack API](https://api.slack.com/)
- Python
- APIs de cÃ¢mbio (ex.: [exchangerate.host](https://exchangerate.host/) ou similares)

## ğŸ“‚ Estrutura do Projeto

```bash
ğŸ“ src/
â”œâ”€â”€ dags/                # DAGs do Airflow
â”œâ”€â”€ scripts/             # Scripts de coleta e transformaÃ§Ã£o
â”œâ”€â”€ notebooks/           # Notebooks do Databricks
â”œâ”€â”€ slack_bot/           # CÃ³digo para envio do relatÃ³rio via Slack
â””â”€â”€ utils/               # FunÃ§Ãµes auxiliares
